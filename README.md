# Police Data Updater

This project fetches, processes, and stores **Stop and Search** data for the **Metropolitan Police Service** using the [UK Police Data API](https://data.police.uk/docs/method/stops-force/).  
It stores all historical stop and search records in CSV format and updates the file daily.

The project also includes a **daily update mechanism** to keep the dataset fresh, unit tests for key functions, and a **Dockerized deployment** for easy portability across environments.

---

## ğŸ“Œ Features

- **Historical Data Fetching** â€“ Download all available stop and search records for a specified police force.
- **Data Cleaning & Formatting** â€“ Standardizes columns, removes duplicates, and ensures clean, ready-to-use datasets.
- **Daily Updates** â€“ Appends new data to the existing dataset without overwriting historical records.
- **Dockerized** â€“ Runs anywhere with Docker, using volume mapping to persist CSV files outside the container.
- **Unit Tests** â€“ Includes test coverage for fetching, updating, and utility functions.
---

## ğŸ“‚ Project Structure

```
stop_search_data/
â”‚â”€â”€ config/                  # Configuration files
â”‚   â””â”€â”€ config.py
â”‚
â”‚â”€â”€ data/                    # CSV output folder (persisted outside container)
â”‚   â””â”€â”€ metropolitan_stops.csv
â”‚
â”‚â”€â”€ src/                     # Core application code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ fetcher.py           # API calls to fetch stop & search data
â”‚   â”œâ”€â”€ logger.py            # Logger utility
â”‚   â”œâ”€â”€ main.py              # Entry point script
â”‚   â”œâ”€â”€ updater.py           # Logic for updating the dataset
â”‚   â””â”€â”€ utils.py             # Helper functions
â”‚
â”‚â”€â”€ tests/                   # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_fetcher.py
â”‚   â”œâ”€â”€ test_updater.py
â”‚   â””â”€â”€ test_utils.py
â”‚
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ docker-compose.yml  # Compose configuration
â”œâ”€â”€ Dockerfile          # Docker build file
â”‚â”€â”€ data_storage_rdms.md     # Database schema documentation
â”‚â”€â”€ data_update.log          # Log file
â”‚â”€â”€ README.md                # Project documentation
```

---

## âš™ï¸ Prerequisites

- [Docker Desktop](https://www.docker.com/products/docker-desktop/) installed and running.
- [Docker Compose](https://docs.docker.com/compose/) installed.

---

## ğŸ“¦ Setup & Run with Docker Compose

### 1ï¸âƒ£ Build and start the service

```bash
docker-compose up --build -d
```

This will:
- Build the image from the `Dockerfile`.
- Mount the `./data` folder so CSV persists outside the container.
- Run the updater daily using a loop.

---

### 2ï¸âƒ£ Check logs

```bash
docker-compose logs -f
```

---

### 3ï¸âƒ£ Stop the service

```bash
docker-compose down
```

---

## ğŸ—‚ Data Persistence

The `data/` folder is mounted as a **Docker volume**.  
When the container stops, the CSV remains available on your local machine.

---

## ğŸ”„ How It Updates Daily

The `docker-compose.yml` contains:

```yaml
command: sh -c "while true; do python src/main.py; sleep 86400; done"
restart: always
```

This ensures:
- The script runs once immediately on startup.
- Waits 24 hours.
- Runs again automatically.

---

## ğŸ§ª Running Tests

From the host machine:

```bash
pytest tests
```

---

## ğŸ›  Tech Stack

- **Python 3.10**
- **Pandas** for data processing
- **Requests** for API calls
- **Docker Compose** for container orchestration

---

## ğŸ—„ Database Schema (Optional)

If storing in a relational database, recommended schema:

- **stops_and_searches**
- **outcomes**
- **locations**
- **streets**

(More details provided [here]())

